# Assignment Details

âš™ï¸ Interprocess Communication for Trading Systems
Overview
In this assignment, you will design and implement a simplified multi-process trading system that uses interprocess communication (IPC) to connect independent components through real TCP sockets and shared memory.
Youâ€™ll build a mini trading stack â€” a Gateway, OrderBook, Strategy, and OrderManager â€” that communicate in real time.

This assignment emphasizes process orchestration, socket programming, serialization, and shared memory synchronization in the context of financial systems.

ðŸŽ¯ Learning Objectives
Understand how to establish and manage socket connections between processes.

Use multiprocessing and socket to build producerâ€“consumer systems.

Apply multiprocessing.shared_memory to share market data efficiently between processes.

Design and implement simple message protocols for structured communication.

Handle serialization, message framing, and synchronization.

ðŸ“‹ Task Specifications
1. System Overview
You will implement four cooperating Python processes:

[ Gateway ] â†’ [ OrderBook ] â†’ [ Strategy ] â†’ [ OrderManager ]

 

Gateway: Streams random tick prices and news sentiment values over sockets.

OrderBook: Receives price data and updates a shared memory store.

Strategy: Reads shared memory and news, decides whether to buy or sell.

OrderManager: Receives orders over a socket and logs executed trades.

All four processes should run concurrently and communicate only through sockets or shared memory â€” no shared Python objects.

2. Gateway (Data & News Feed)
Responsibilities:

Acts as a server that broadcasts two streams:

Price stream: A random-walk price feed for multiple symbols. You can build this yourself, or you can use the csv file from the previous homework as the price data you will stream.

News sentiment: Integers between 0â€“100, representing market sentiment. Low values represent bad news while high values represent good news. A sentiment of 50 is neutral. You will be the news server yourself that will randomly choose a news sentiment value to stream.

Uses TCP sockets to send data to connected clients (OrderBook and Strategy).

Expectations:

Use the socket module.

Send serialized messages delimited by a consistent MESSAGE_DELIMITER (e.g. b'*').

Example message:
b"AAPL,172.53*MSFT,325.20*"

3. OrderBook (Shared Market State)
Responsibilities:

Connects to the Gateway to receive price data.

Maintains the latest prices for all symbols in shared memory.

Provides shared memory access to the Strategy process.

Expectations:

Use multiprocessing.shared_memory to store and update a NumPy structured array, or a serialized dictionary of {symbol: price}.

Ensure updates are atomic and synchronized using multiprocessing.Lock.

Handle reconnection logic gracefully if the Gateway restarts.

4. Strategy (Signal Generator)
Responsibilities:

Reads the latest prices from shared memory.

Connects to the Gatewayâ€™s news stream to receive sentiment.

Generates trading signals:

Price-based: Moving average crossover (short vs long window). If the short moving average is above the long moving average you should generate a buy signal, otherwise a sell signal. The condition for buy or sell is strictly greater than or less than. Don't worry about the case where they are equal.

News-based: Sentiment > bullish_threshold â†’ Buy signal; Sentiment < bearish_threshold â†’ Sell signal.

Only act when both signals agree - when news signal and price signal are both buy, you buy; if they are both sell, you sell; and if they are different you do nothing.

Sends an Order message to the OrderManager when a trade is decided.

Expectations:

Use a local rolling buffer for price history.

Manage current position (None, long, short) to avoid duplicate orders.

Serialize orders before sending (e.g. JSON, pickle, or otherwise).

Respect MESSAGE_DELIMITER in all transmissions.

5. OrderManager (Trade Execution)
Responsibilities:

Acts as a TCP server receiving Order objects from one or more Strategy clients.

Deserialize each order and log the trade.

Print human-readable trade confirmations in real time:

Received Order 12: BUY 10 AAPL @ 173.20

6. Shared Memory Interface
Create a helper class for structured memory access:

class SharedPriceBook:

    def __init__(self, symbols, name=None):

        ...

    def update(self, symbol, price):

        ...

    def read(self, symbol):

        ...

 

Use multiprocessing.shared_memory.SharedMemory and np.ndarray for efficient updates.

7. Orchestration (main.py)
Your main.py should start each process and manage startup order:

if __name__ == "__main__":

    processes = [

        Process(target=run_gateway),

        Process(target=run_orderbook),

        Process(target=run_strategy),

        Process(target=run_ordermanager)

    ]

    for p in processes: p.start()

    for p in processes: p.join()

 

8. Performance & Reliability
Measure:

Average latency between a new price tick and a trade decision.

Throughput (ticks per second).

Memory footprint of the shared memory region.

Behavior under dropped connections or missing data.

ðŸ§ª Unit Tests
Write tests to confirm:

Connections establish successfully between components.

Messages are serialized/deserialized correctly.

Shared memory updates propagate as expected.

Strategy generates correct buy/sell/neutral signals.

OrderManager receives and logs the correct number of orders.

ðŸ“¦ Deliverables
ðŸ‘‰ Please share your GitHub with your TAs:

Jenn: jcolli5158
Hunter: hyoung3
File

Description

gateway.py

Streams price & sentiment data via TCP

orderbook.py

Receives prices and maintains shared memory

strategy.py

Generates trading signals and sends orders

order_manager.py

Receives and logs executed trades

shared_memory_utils.py

Defines shared memory wrapper

main.py

Launches all processes

tests/

Unit tests for connectivity and correctness

performance_report.md

Latency & throughput benchmarks

README.md

Architecture diagram and run instructions

video.mp4

You will also need to share a video of the system in action. Show the processes running independently, separate logs, etc. How you do this is up to you, but it should show are the parts in action together.

You may also include any other files you think are necessary for running the project. 

Please document your project well.


# Submission
Gateway (TCP Server)

â”œâ”€â”€ Price stream (port 5001)

â”œâ”€â”€ News sentiment stream (port 5002)

â†“

OrderBook (Client)

â””â”€â”€ Updates shared memory (latest prices)

Strategy (Client)

â”œâ”€â”€ Reads shared memory prices

â”œâ”€â”€ Listens to sentiment feed

â””â”€â”€ Sends orders â†’ OrderManager

OrderManager (TCP Server)

â””â”€â”€ Logs executed trades in real time


---

## Components

| File | Description |
|------|--------------|
| `gateway.py` | Streams random-walk prices + random sentiment values. |
| `orderbook.py` | Subscribes to Gateway, maintains a shared NumPy price book. |
| `strategy.py` | Reads shared memory, applies **moving average + sentiment** signals. |
| `order_manager.py` | Receives and logs orders from Strategy clients. |
| `shared_memory_utils.py` | Defines `SharedPriceBook` helper and socket message utilities. |
| `main.py` | Orchestrates all processes (runs the entire system). |
| `tests/` | Unit tests for connectivity, shared memory, and strategy logic. |
| `performance_report.md` | Contains latency and throughput measurements. |
| `video.mp4` | Demo of the live system running independently. |

---

## How to Run

```bash
python -m venv .venv && source .venv/bin/activate
pip install -U pip numpy pytest
python main.py
